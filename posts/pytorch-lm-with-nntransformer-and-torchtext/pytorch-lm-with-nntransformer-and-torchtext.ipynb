{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9f7418fc",
   "metadata": {},
   "source": [
    "---\n",
    "title: Language Modeling with nn.Transformer and Torchtext\n",
    "date: 2023-03-11\n",
    "format:\n",
    "  html:\n",
    "    code-fold: false\n",
    "jupyter: python3\n",
    "categories:\n",
    "  - pytorch\n",
    "  - pytorch-tutorial\n",
    "  - nlp\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8995a020",
   "metadata": {},
   "source": [
    "출처 : [PyTorch Transformer](https://pytorch.org/tutorials/beginner/basics/transforms_tutorial.html)\n",
    "\n",
    "이 튜토리얼은 [nn.Transformer](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html) 모듈을 사용해서 seq2seq 학습에 대해 다룬다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d5acdb",
   "metadata": {},
   "source": [
    "PyTorch 1.2부터 [Attention is All You Need](https://arxiv.org/pdf/1706.03762.pdf) 논문에 기반한 표준 transformer 모듈이 포함된다. Recurrent Neural Networks (RNNs)와 비교해서, transformer 모델이 seq2seq 작업에 더 효과적이라는 것이 증명되었다. `nn.Transformer` 모듈은 input과 output 사이의 전역 의존성을 이끌어내기 위해 attention mechchanism ([nn.MultiheadAttention](https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html)에서 구현)을 사용한다. `nn.Transformer` 모듈은 고도로 모듈화가 되어 있어 단일 컴포넌트 (예, [nn.TransformerEncoder](https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html))를 쉽게 조정하거나 구성할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00fefc0",
   "metadata": {},
   "source": [
    "![transformer](https://pytorch.org/tutorials/_images/transformer_architecture.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b366c1",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "이 튜토리얼에서, language modeling 작업용으로 `nn.TransformerEncoder`를 학습한다. Language modeling 작업이란 주어진 단어(또는 단어 sequence)가 앞의 단어 sequence를 따를 가능성에 대한 확률을 구한다. 우선 토큰 sequence는 embedding layer로 전달된 다음, 단어 순서를 설명하기 위해 positional encoding layer로 전달된다 (자세한 설명은 다음 문단에). `nn.TransformerEncoder`는 여러 개의 [nn.TransformerEncoderLayer](https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoderLayer.html)로 이루어져 있다. input sequence와 함께 정사각형 attention mask가 필요한데, 왜냐하면 `nn.TransformerEncoder`의 self-attention layer는 input sequence의 앞부분에만 적용되기 때문이다. Language modeling 작업에서 뒷부분의 토큰은 마스킹되어야 한다. output 단어들의 확률분포를 생성하기 위해서는, `nn.TransformerEncoder`의 output은 linear layer를 통과한 후 log-softmax function을 거친다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9050b130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "        \"\"\"\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
    "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45628fe",
   "metadata": {},
   "source": [
    "`PositionalEncoding` 모듈은 sequence에 있는 토큰들의 상대적이거나 절대적인 위치에 대한 정보를 주입한다. Positional encodings는 embeddings와 동일한 dimension을 갖고 있어서 같이 더할 수 있다. 아래의 코드는 `sin`, `cos` functions를 사용해서 positional encoding에 대한 구현이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f05a1935",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c3897",
   "metadata": {},
   "source": [
    "## Load and batch data\n",
    "이 튜토리얼은 Wikitext-2 dataset를 생성하기 위해 `torchtext`를 사용한다. torchtext datasets를 사용하기 위해서는 다음과 같은 명령어로 torchdata를 설치한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e120f852",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install torchdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e847c2",
   "metadata": {},
   "source": [
    "vocab 객체는 train dataset을 기반으로 만들고 토큰을 수치화해서 tensor로 만들기위해 사용된다. Wikitext-2는 희귀한 토큰을 `<unk>`로 표현한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfe08a3",
   "metadata": {},
   "source": [
    "1-D vector로 이루어진 순서 데이터가 주어지면, `batchify()`는 데이터를 `batch_size` column 수만큼 배열한다. 만약 데이터가 `batch_size` column 수만큼 나누어 떨이지지 않는다면, 데이터를 자른다. 예를들어, 길이가 26인 알파벳 data가 있고 `batch_size=4`라면, 알파벳을 길이가 6인 sequences 4개를 만든다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f320f505",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix}\n",
    "A & B & C & \\cdots & X & Y & Z\n",
    "\\end{bmatrix}\n",
    "\\Rightarrow\n",
    "\\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "A \\\\ B \\\\ C \\\\ D \\\\ E \\\\ F\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "G \\\\ H \\\\ I \\\\ J \\\\ K \\\\ L\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "M \\\\ N \\\\ O \\\\ P \\\\ Q \\\\ R\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "S \\\\ T \\\\ U \\\\ V \\\\ W \\\\ X\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd08d110",
   "metadata": {},
   "source": [
    "Batching은 병렬처리를 가능하게 하지만, 각 column을 독립척으로 처리한다. 그래서 `G`와 `F`의 의존성은 위의 예에서 학습할 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a6e3751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "train_iter = WikiText2(split='train')\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
    "    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
    "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
    "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "\n",
    "# train_iter was \"consumed\" by the process of building the vocab,\n",
    "# so we have to create it again\n",
    "train_iter, val_iter, test_iter = WikiText2()\n",
    "train_data = data_process(train_iter)\n",
    "val_data = data_process(val_iter)\n",
    "test_data = data_process(test_iter)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def batchify(data: Tensor, bsz: int) -> Tensor:\n",
    "    \"\"\"Divides the data into bsz separate sequences, removing extra elements\n",
    "    that wouldn't cleanly fit.\n",
    "\n",
    "    Args:\n",
    "        data: Tensor, shape [N]\n",
    "        bsz: int, batch size\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape [N // bsz, bsz]\n",
    "    \"\"\"\n",
    "    seq_len = data.size(0) // bsz\n",
    "    data = data[:seq_len * bsz]\n",
    "    data = data.view(bsz, seq_len).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "batch_size = 20\n",
    "eval_batch_size = 10\n",
    "train_data = batchify(train_data, batch_size)  # shape [seq_len, batch_size]\n",
    "val_data = batchify(val_data, eval_batch_size)\n",
    "test_data = batchify(test_data, eval_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379f3be2",
   "metadata": {},
   "source": [
    "### Functions to generate input and target sequence\n",
    "`get_batch()`는 transformer model을 위한 input-target sequences를 생성한다. `get_batch()`는 소스 데이터를 `bptt` 길이의 chunks로 세분화한다. Language modeling 작업을 위해, model은 `Target`이라는 미래 단어들이 필요하다. 예를들어, `bptt`가 2라면, `i=0`일 때의 2개의 미래 단어를 얻을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53713395",
   "metadata": {},
   "source": [
    "![matrix](https://pytorch.org/tutorials/_images/transformer_input_target.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cf9402",
   "metadata": {},
   "source": [
    "(batch마다 2개의 단어를 묶어야 하므로 input (A,B), target (B,C), input (G, H), target (H, I), ... 로 row가 아니라 column으로 같이 묶여야 한다. 위의 행렬에 오류 있음.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021a4060",
   "metadata": {},
   "source": [
    "chunks는 데이터의 0번째 차원에 있다는 것을 유의해야한다. batch는 1번째 차원에 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbaa5a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 35\n",
    "def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        source: Tensor, shape [full_seq_len, batch_size]\n",
    "        i: int\n",
    "\n",
    "    Returns:\n",
    "        tuple (data, target), where data has shape [seq_len, batch_size] and\n",
    "        target has shape [seq_len * batch_size]\n",
    "    \"\"\"\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1d8e68",
   "metadata": {},
   "source": [
    "## Initiate an instance\n",
    "model hyperparameters는 아래에 정의되어 있다. vocab size는 vocab object와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff71f3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(vocab)  # size of vocabulary\n",
    "emsize = 200  # embedding dimension\n",
    "d_hid = 200  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2  # number of heads in nn.MultiheadAttention\n",
    "dropout = 0.2  # dropout probability\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0851931",
   "metadata": {},
   "source": [
    "## Run the model\n",
    "학습은 [SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html) (stochastic gradient descent) optimizer를 사용하고 loss function으로 [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)를 사용한다. learning rate는 5.0으로 초기화하고 [StepLR](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html)을 사용해 schedule을 한다. 학습하는 동안 [nn.utils.clip_grad_norm_](https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html)을 사용해 gradient exploding을 방지한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3bc3751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5.0  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "def train(model: nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.\n",
    "    log_interval = 200\n",
    "    start_time = time.time()\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "\n",
    "    num_batches = len(train_data) // bptt\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        seq_len = data.size(0)\n",
    "        if seq_len != bptt:  # only on last batch\n",
    "            src_mask = src_mask[:seq_len, :seq_len]\n",
    "        output = model(data, src_mask)\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
    "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
    "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, eval_data.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(eval_data, i)\n",
    "            seq_len = data.size(0)\n",
    "            if seq_len != bptt:\n",
    "                src_mask = src_mask[:seq_len, :seq_len]\n",
    "            output = model(data, src_mask)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += seq_len * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(eval_data) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c603ae",
   "metadata": {},
   "source": [
    "epoch를 돌면서 이때까지 본 것 중 validation loss가 가장 좋다면 모델을 저장한다. 또 각 epoch마다 learning rate를 조절한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "876a4750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   200/ 2928 batches | lr 5.00 | ms/batch 26.08 | loss  8.23 | ppl  3737.76\n",
      "| epoch   1 |   400/ 2928 batches | lr 5.00 | ms/batch 11.58 | loss  6.92 | ppl  1010.80\n",
      "| epoch   1 |   600/ 2928 batches | lr 5.00 | ms/batch 11.46 | loss  6.47 | ppl   645.55\n",
      "| epoch   1 |   800/ 2928 batches | lr 5.00 | ms/batch 11.28 | loss  6.32 | ppl   555.72\n",
      "| epoch   1 |  1000/ 2928 batches | lr 5.00 | ms/batch 11.52 | loss  6.20 | ppl   493.80\n",
      "| epoch   1 |  1200/ 2928 batches | lr 5.00 | ms/batch 11.46 | loss  6.17 | ppl   479.33\n",
      "| epoch   1 |  1400/ 2928 batches | lr 5.00 | ms/batch 11.43 | loss  6.12 | ppl   455.35\n",
      "| epoch   1 |  1600/ 2928 batches | lr 5.00 | ms/batch 11.58 | loss  6.11 | ppl   451.57\n",
      "| epoch   1 |  1800/ 2928 batches | lr 5.00 | ms/batch 11.61 | loss  6.04 | ppl   419.10\n",
      "| epoch   1 |  2000/ 2928 batches | lr 5.00 | ms/batch 11.65 | loss  6.02 | ppl   412.79\n",
      "| epoch   1 |  2200/ 2928 batches | lr 5.00 | ms/batch 11.67 | loss  5.90 | ppl   364.81\n",
      "| epoch   1 |  2400/ 2928 batches | lr 5.00 | ms/batch 11.43 | loss  5.98 | ppl   393.81\n",
      "| epoch   1 |  2600/ 2928 batches | lr 5.00 | ms/batch 11.53 | loss  5.96 | ppl   386.26\n",
      "| epoch   1 |  2800/ 2928 batches | lr 5.00 | ms/batch 11.36 | loss  5.88 | ppl   356.50\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 38.00s | valid loss  5.78 | valid ppl   325.14\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |   200/ 2928 batches | lr 4.75 | ms/batch 11.61 | loss  5.87 | ppl   355.89\n",
      "| epoch   2 |   400/ 2928 batches | lr 4.75 | ms/batch 11.62 | loss  5.86 | ppl   349.88\n",
      "| epoch   2 |   600/ 2928 batches | lr 4.75 | ms/batch 11.48 | loss  5.67 | ppl   288.70\n",
      "| epoch   2 |   800/ 2928 batches | lr 4.75 | ms/batch 11.40 | loss  5.71 | ppl   301.53\n",
      "| epoch   2 |  1000/ 2928 batches | lr 4.75 | ms/batch 11.54 | loss  5.66 | ppl   287.14\n",
      "| epoch   2 |  1200/ 2928 batches | lr 4.75 | ms/batch 11.68 | loss  5.69 | ppl   294.82\n",
      "| epoch   2 |  1400/ 2928 batches | lr 4.75 | ms/batch 11.46 | loss  5.69 | ppl   297.15\n",
      "| epoch   2 |  1600/ 2928 batches | lr 4.75 | ms/batch 11.45 | loss  5.72 | ppl   303.57\n",
      "| epoch   2 |  1800/ 2928 batches | lr 4.75 | ms/batch 11.51 | loss  5.65 | ppl   285.06\n",
      "| epoch   2 |  2000/ 2928 batches | lr 4.75 | ms/batch 11.31 | loss  5.66 | ppl   288.08\n",
      "| epoch   2 |  2200/ 2928 batches | lr 4.75 | ms/batch 11.41 | loss  5.55 | ppl   258.10\n",
      "| epoch   2 |  2400/ 2928 batches | lr 4.75 | ms/batch 11.52 | loss  5.65 | ppl   284.08\n",
      "| epoch   2 |  2600/ 2928 batches | lr 4.75 | ms/batch 11.59 | loss  5.64 | ppl   282.13\n",
      "| epoch   2 |  2800/ 2928 batches | lr 4.75 | ms/batch 11.51 | loss  5.57 | ppl   262.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 35.02s | valid loss  5.67 | valid ppl   290.63\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |   200/ 2928 batches | lr 4.51 | ms/batch 11.32 | loss  5.60 | ppl   271.62\n",
      "| epoch   3 |   400/ 2928 batches | lr 4.51 | ms/batch 11.36 | loss  5.63 | ppl   277.62\n",
      "| epoch   3 |   600/ 2928 batches | lr 4.51 | ms/batch 11.55 | loss  5.43 | ppl   227.22\n",
      "| epoch   3 |   800/ 2928 batches | lr 4.51 | ms/batch 11.58 | loss  5.48 | ppl   240.90\n",
      "| epoch   3 |  1000/ 2928 batches | lr 4.51 | ms/batch 11.22 | loss  5.44 | ppl   229.37\n",
      "| epoch   3 |  1200/ 2928 batches | lr 4.51 | ms/batch 11.36 | loss  5.48 | ppl   239.41\n",
      "| epoch   3 |  1400/ 2928 batches | lr 4.51 | ms/batch 11.41 | loss  5.49 | ppl   241.50\n",
      "| epoch   3 |  1600/ 2928 batches | lr 4.51 | ms/batch 11.32 | loss  5.52 | ppl   248.71\n",
      "| epoch   3 |  1800/ 2928 batches | lr 4.51 | ms/batch 11.37 | loss  5.46 | ppl   235.82\n",
      "| epoch   3 |  2000/ 2928 batches | lr 4.51 | ms/batch 11.32 | loss  5.48 | ppl   240.72\n",
      "| epoch   3 |  2200/ 2928 batches | lr 4.51 | ms/batch 11.28 | loss  5.35 | ppl   211.17\n",
      "| epoch   3 |  2400/ 2928 batches | lr 4.51 | ms/batch 11.23 | loss  5.46 | ppl   234.29\n",
      "| epoch   3 |  2600/ 2928 batches | lr 4.51 | ms/batch 11.37 | loss  5.46 | ppl   235.63\n",
      "| epoch   3 |  2800/ 2928 batches | lr 4.51 | ms/batch 11.36 | loss  5.40 | ppl   221.16\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 34.61s | valid loss  5.62 | valid ppl   276.85\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "epochs = 3\n",
    "\n",
    "with TemporaryDirectory() as tempdir:\n",
    "    best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train(model)\n",
    "        val_loss = evaluate(model, val_data)\n",
    "        val_ppl = math.exp(val_loss)\n",
    "        elapsed = time.time() - epoch_start_time\n",
    "        print('-' * 89)\n",
    "        print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
    "            f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
    "        print('-' * 89)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "        scheduler.step()\n",
    "    model.load_state_dict(torch.load(best_model_params_path)) # load best model states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a4d584",
   "metadata": {},
   "source": [
    "## Evaluate the best model on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8eb9b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss  5.53 | test ppl   252.38\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(model, test_data)\n",
    "test_ppl = math.exp(test_loss)\n",
    "print('=' * 89)\n",
    "print(f'| End of training | test loss {test_loss:5.2f} | '\n",
    "      f'test ppl {test_ppl:8.2f}')\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74b1ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
